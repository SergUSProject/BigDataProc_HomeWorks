## **<u>Домашнее задание 1.</u>**

### Цель. Создание распределенного вычислительного кластера на базе программных средств Apache Hadoop.

##### Задачи:

1. Создание `Docker`-контейнеров, включающих основные программные компоненты файловой системы Hadoop.`HDFS`.
2. Добавление инструкций и конфигурация (настройка) установленных в контейнеры компонент для 
   выполнения ими соответствующих ролей в распределенном кластере.
3. Конфигурация (настройка) взаимосвязи между узлами (запущенными образами) распределенного кластера.
4. Проверка работоспособности созданного вычислительного кластера.

##### Предлагаемые этапы выполнения задания:

Этап 1. Установка `Docker`. 
Этап 2. Создание базового образа `Hadoop`.
Этап 3. Сборка образов Hadoop Master и Worker 
Этап 4. Развертывание сборки с помощью `Docker Compose`

##### Необходимое программное обеспечение:

- Дистрибутив Docker (официальный сайт: https://www.docker.com/).
- Программные компоненты, необходимые для функционирования узлов кластера, определены в [разделах практики](https://github.com/SergUSProject/BigDataProcSystems_practice).

##### Результат:

​    Функционирующий (т.е. запущены все необходимые службы, выполняются все команды, доступны Web-интерфейсы компонент) распределенный кластер на базе файловой системы `hdfs`.

##### Описание возможного варианта решения:

![Структура (архитектура) кластера](./img/docker/cluster_architecture.png)

​                                                                Рисунок 1. Структура (архитектура) кластера

 
![Cтруктура контейнера](./img/docker/cluster_containers.png)

​                                                                         Рисунок 2. Структура контейнера



![Структура образов](./img/docker/cluster_images.png)

​                                                                              Рисунок 3. Структура образов



##### Этап 1. Установка `Docker` ([инструкция по установке](https://docs.docker.com/engine/install/ubuntu/)).

##### Этап 2. Сборка `Docker`-файла на Ubuntu.

​	Необходимо взять базовый образ `ubuntu` и добавить инструкции так же, как это было сделано на виртуальной машине.
​	В `Dockerfile` необходимо:

 - установить `OpenSHH` и `Java 8`
 - создать пользователя без root-привилегий
 - загрузить архив дистрибутива `Hadoop` и распаковать его
 - скопировать/создать подготовленные файлы конфигурации `Hadoop`
 - скопировать скрипт `entrypoint.sh` 
 - применить сценарий `entrypoint.sh`

шаблон `Docker`-файла можно найти здесь (ссылка)

Сценарий [`entrypoint.sh`](./base/entrypoint.sh) который содержит скрипт запуска службы `SSH` и демонов `Namemode` и `Datanode`
запуск компиляции образа производится командой `docker build`

##### Этап 3. 

##### 	Сборка `Master Image`. 

 Вариант [`Docker`-файла](./master/Dockerfile) 
 Пример сценария [`entrypoint.sh`](./master/entrypoint.sh) 

 Компиляции образа производится командой `docker build`

#####  	Сборка `Worker Image`. 

 Вариант [`Docker`-файла](./worker/Dockerfile)
 Пример сценария [`entrypoint.sh`](./worker/entrypoint.sh) 

 Компиляции образа производится командой `docker build`

##### Этап 4. Создать файл `docker-compose.yml` ([например](./HomeWork_1/docker-compose.yml))

Развернуть кластер `Hadoop`. Выполните следующую команду, чтобы развернуть `Master` и 4 `Workers`:

`docker-compose up -d --scale worker=4`        
