<?xml version="1.0"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->
<configuration>

  	<!-- Resource Manager Configuration -->

  	<property>
    	<description>The hostname of the RM.</description>
    	<name>yarn.resourcemanager.hostname</name>
    	<value>master</value>
  	</property>
	<property>
    	<description>The address of the applications manager interface in the RM.</description>
    	<name>yarn.resourcemanager.address</name>
    	<value>${yarn.resourcemanager.hostname}:8032</value>
  	</property>
  	<property>
    	<description>The class to use as the resource scheduler.</description>
    	<name>yarn.resourcemanager.scheduler.class</name>
    	<value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler</value>
  	</property>
	<property>
	    <description>Amount of physical memory, in MB, that can be allocated 
		for containers. If set to -1 and
		yarn.nodemanager.resource.detect-hardware-capabilities is true, it is
		automatically calculated(in case of Windows and Linux).
		In other cases, the default is 8192MB.
		</description>
		<name>yarn.nodemanager.resource.memory-mb</name>
		<value>4096</value>
	</property>
	<property>
		<description>The minimum allocation for every container request at the RM
		in MBs. Memory requests lower than this will be set to the value of this
		property. Additionally, a node manager that is configured to have less memory
		than this value will be shut down by the resource manager.</description>
		<name>yarn.scheduler.minimum-allocation-mb</name>
		<value>512</value>
	</property>
	<property>
		<description>The maximum allocation for every container request at the RM
		in MBs. Memory requests higher than this will throw an
		InvalidResourceRequestException.</description>
		<name>yarn.scheduler.maximum-allocation-mb</name>
		<value>2048</value>
	</property>
  	<property>
    	<description>The heart-beat interval in milliseconds for every NodeManager in the cluster.</description>
    	<name>yarn.resourcemanager.nodemanagers.heartbeat-interval-ms</name>
    	<value>1000</value>
  	</property>
	<property>
		<description>The minimum allocation for every container request at the RM
		in terms of virtual CPU cores. Requests lower than this will be set to the
		value of this property. Additionally, a node manager that is configured to
		have fewer virtual cores than this value will be shut down by the resource
		manager.</description>
		<name>yarn.scheduler.minimum-allocation-vcores</name>
		<value>1</value>
	</property>
	<property>
		<description>The maximum allocation for every container request at the RM
		in terms of virtual CPU cores. Requests higher than this will throw an
		InvalidResourceRequestException.</description>
		<name>yarn.scheduler.maximum-allocation-vcores</name>
		<value>4</value>
	</property>

	<!-- Node Manager Configuration -->

  	<property>
    	<description>The hostname of the NM.</description>
    	<name>yarn.nodemanager.hostname</name>
    	<value>0.0.0.0</value>
  	</property>
    <property>
    	<description>The address of the container manager in the NM.</description>
    	<name>yarn.nodemanager.address</name>
    	<!--<value>${yarn.nodemanager.hostname}:0</value>-->
		<value>${yarn.nodemanager.hostname}:45454</value>
  	</property>
  	<property>
		<description>List of directories to store localized files in. An 
		application's localized file directory will be found in:
		${yarn.nodemanager.local-dirs}/usercache/${user}/appcache/application_${appid}.
		Individual containers' work directories, called container_${contid}, will
		be subdirectories of this.
		</description>
    	<name>yarn.nodemanager.local-dirs</name>
    	<value>${hadoop.tmp.dir}/nm-local-dir</value>
  	</property>
	<property>
		<description>
		Where to store container logs. An application's localized log directory
		will be found in ${yarn.nodemanager.log-dirs}/application_${appid}.
		Individual containers' log directories will be below this, in directories 
		named container_{$contid}. Each container directory will contain the files
		stderr, stdin, and syslog generated by that container.
		</description>
		<name>yarn.nodemanager.log-dirs</name>
		<value>${yarn.log.dir}/userlogs</value>
	</property>
	<property>
		  <name>yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage</name>
		  <value>98</value>
	</property>
	<property>
		<name>yarn.nodemanager.pmem-check-enabled</name>
		<value>false</value>
	</property>
	<property>
		 <name>yarn.nodemanager.vmem-check-enabled</name>
		 <value>false</value>
	</property>


  	<!-- Map Reduce Configuration -->

	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
	</property>
	<property>
		<name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
		<value>org.apache.hadoop.mapred.ShuffleHandler</value>
	</property>

	<!-- Applications' Configuration -->

	<property>
		<description>
		CLASSPATH for YARN applications. A comma-separated list
		of CLASSPATH entries. When this value is empty, the following default
		CLASSPATH for YARN applications would be used. 
		For Linux:
		$HADOOP_CONF_DIR,
		$HADOOP_COMMON_HOME/share/hadoop/common/*,
		$HADOOP_COMMON_HOME/share/hadoop/common/lib/*,
		$HADOOP_HDFS_HOME/share/hadoop/hdfs/*,
		$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*,
		$HADOOP_YARN_HOME/share/hadoop/yarn/*,
		$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*
		For Windows:
		%HADOOP_CONF_DIR%,
		%HADOOP_COMMON_HOME%/share/hadoop/common/*,
		%HADOOP_COMMON_HOME%/share/hadoop/common/lib/*,
		%HADOOP_HDFS_HOME%/share/hadoop/hdfs/*,
		%HADOOP_HDFS_HOME%/share/hadoop/hdfs/lib/*,
		%HADOOP_YARN_HOME%/share/hadoop/yarn/*,
		%HADOOP_YARN_HOME%/share/hadoop/yarn/lib/*
		</description>
		<name>yarn.application.classpath</name>
		<value></value>
	</property>

	<!--Capacity Scheduler container preemption-->

	<property>
		<description>Enable a set of periodic monitors (specified in
			yarn.resourcemanager.scheduler.monitor.policies) that affect the
			scheduler.</description>
		<name>yarn.resourcemanager.scheduler.monitor.enable</name>
		<value>true</value>
	</property>
	<property>
		<description>The list of SchedulingEditPolicy classes that interact with
			the scheduler. A particular module may be incompatible with the
			scheduler, other policies, or a configuration of either.</description>
		<name>yarn.resourcemanager.scheduler.monitor.policies</name>
		<value>org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy</value>
	</property>
</configuration>
